{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import math\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style(theme='monokai')\n",
    "jtplot.style(context='talk', fscale=1.4, spines=False, gridlines='--')\n",
    "jtplot.style(ticks=True, grid=False, figsize=(10, 10))\n",
    "import datetime\n",
    "from psaw import PushshiftAPI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = PushshiftAPI()\n",
    "features = [\"title\", \"id\", \"score\", \"author\", \"created_utc\", \"selftext\"]\n",
    "subreddit = \"asoiaf\"\n",
    "date1 = int(datetime.datetime(2015,7,16).timestamp())\n",
    "date2 = int(datetime.datetime(2019,4,14).timestamp())\n",
    "gen = api.search_submissions(subreddit = subreddit, after = date1, before = date2, q='', filter = features, limit = 3 * 10**5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oskar/.local/lib/python3.9/site-packages/psaw/PushshiftAPI.py:192: UserWarning: Got non 200 code 429\n",
      "  warnings.warn(\"Got non 200 code %s\" % response.status_code)\n",
      "/home/oskar/.local/lib/python3.9/site-packages/psaw/PushshiftAPI.py:180: UserWarning: Unable to connect to pushshift.io. Retrying after backoff.\n",
      "  warnings.warn(\"Unable to connect to pushshift.io. Retrying after backoff.\")\n"
     ]
    }
   ],
   "source": [
    "results = list(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ids, title, score, author, created_utc, selftext = [], [], [], [], [], []\n",
    "for i in range(len(results)):\n",
    "    try:\n",
    "        selftext.append(results[i].d_['selftext'])\n",
    "        ids.append(i)\n",
    "        title.append(results[i].d_['title'])\n",
    "        score.append(results[i].d_['score'])\n",
    "        created_utc.append(results[i].d_['created_utc'])\n",
    "        author.append(results[i].d_['author'])\n",
    "    except KeyError:\n",
    "        pass\n",
    "        \n",
    "\n",
    "data = pd.DataFrame(\n",
    "{\n",
    "    \"id\" : ids,\n",
    "    \"title\" : title,\n",
    "    \"score\" : score,\n",
    "    \"created\" : created_utc,\n",
    "    \"author\" : author,\n",
    "    \"selftext\" : selftext\n",
    "}, index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72090"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see amount of posts that acutally has text in selftext\n",
    "def get_usefull_data():\n",
    "    text_list = [text for text in data['selftext'] if text != '' ]\n",
    "    text_list = [text for text in text_list if text != '[removed]' ]\n",
    "    return len(text_list)\n",
    "get_usefull_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('asioaf_data.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
